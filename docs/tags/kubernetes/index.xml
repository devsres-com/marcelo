<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>kubernetes on </title>
    <link>https://devsres.com/marcelo/tags/kubernetes/</link>
    <description>Recent content in kubernetes on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt</language>
    <lastBuildDate>Wed, 09 Dec 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://devsres.com/marcelo/tags/kubernetes/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kubernetes on-premises - parte 1</title>
      <link>https://devsres.com/marcelo/blog/kubernetes-on-prem-1/</link>
      <pubDate>Wed, 09 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://devsres.com/marcelo/blog/kubernetes-on-prem-1/</guid>
      <description>Recentemente, participei do Kubicast, em que pude desabafar um pouco com o João Brito da Getup sobre como é criar e um cluster Kubernetes em um ambiente tecnologicamente inóspito e oposto ao universo super estável, escalável e redundante dos cloud providers.
Recebi algumas mensagens de alguns poucos valentes que precisam trilhar esse caminho. Mas, antes, vou ressaltar uma coisa importante: neste primeiro momento, eu vou abordar a história do que foi feito e compartilhar a experiência.</description>
    </item>
    
    <item>
      <title>Calico, Linux e tabelas de rota</title>
      <link>https://devsres.com/marcelo/blog/calico-and-route-tables/</link>
      <pubDate>Tue, 01 Dec 2020 00:00:00 +0000</pubDate>
      
      <guid>https://devsres.com/marcelo/blog/calico-and-route-tables/</guid>
      <description>Mudança no ambiente! Atualização de cada um dos 32 componentes do cluster Kubernetes. Tranquilo! O que pode dar errado?
Após a estabilização do ambiente, começamos a atualização dos servidores que atuam como balanceadores de carga de entrada para o cluster - aqueles que executam o Haproxy Ingress Controller do dev hero João Morais.
A métrica de erros começa a estourar do nada; e o melhor, em tese, não estamos recebendo nenhum erro - algo quebrou, e algo completamente desconhecido.</description>
    </item>
    
    <item>
      <title>De repente, CKA</title>
      <link>https://devsres.com/marcelo/blog/suddenly-cka/</link>
      <pubDate>Wed, 28 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://devsres.com/marcelo/blog/suddenly-cka/</guid>
      <description>Com alguns anos de atraso&amp;hellip;
A história com Kubernetes e seus colegas Cloud Native vem de 2016 quando a área em que estava acabou e a equipe inteira seria &amp;ldquo;despejada&amp;rdquo; em uma área qualquer. Um grupo dissidente da empresa estava procurando almas perdidas e desenganadas para participar de um projeto esquisito, que, segundo eles, seria altamente diferenciado.
Nenhuma grande empresa de tecnologia jamais dedicaria esforço montando uma infraestrutura alternativa com um software de nome estranho que pouca gente do corpo gerencial sequer ouviu falar, ainda mais mantido por uma &amp;ldquo;skeleton crew&amp;rdquo; de poucos nomes desconihecidos.</description>
    </item>
    
    <item>
      <title>Calicoctl, TLS e gestão de certificados</title>
      <link>https://devsres.com/marcelo/blog/calicoctl-stuck/</link>
      <pubDate>Tue, 06 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>https://devsres.com/marcelo/blog/calicoctl-stuck/</guid>
      <description>Estava precisando configurar algumas GlobalNetworkPolicies em um cluster Kubernetes; para isso, é necessário intervir diretamente no Calico, pois o Kubernetes ainda não conta com objetos de Networkpolicies que não sejam &amp;lsquo;namespaced&amp;rsquo;.
Obviamente, usamos &amp;lsquo;backend&amp;rsquo; ETCD: por que simplificaríamos tudo usando CRDs no próprio Kubernetes, não é? Deixamos isso para os amadores!
(PS: fazemos assim porque somos tão pioneiros em usar tecnologias &amp;lsquo;bleeding edge&amp;rsquo; que, à época da implantação, usar Kubernetes como backend sequer era uma opção - sim, nós somos &amp;lsquo;that old school&amp;rsquo;!</description>
    </item>
    
  </channel>
</rss>
